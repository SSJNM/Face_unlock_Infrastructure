{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Program with  Harrcascade and LBPH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install the following Libraries:\n",
    "### opencv_python==4.2.0.32\n",
    "### opencv-contrib-python==4.2.0.32\n",
    "### numpy\n",
    "### subprocess\n",
    "### smtplib \n",
    "### ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1 - Dataset Collection using Haarcascade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Loading Cascade Model using CascadeClassifier as Internal function of OpenCV\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Creating Function to capture images that returns cropped gray images in case face is detected \n",
    "def face_extractor(img):\n",
    "    #Converting Image to Gray    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #Detecting the edges for rectangular region\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Cropping faces if found so as to use for training\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initializing Webcam for Image Capture\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of face from webcam\n",
    "while True:\n",
    "    #Capturing Frames\n",
    "    status, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        #Image Processing\n",
    "        face = cv2.resize(face_extractor(frame), (250, 250))\n",
    "        ##face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = 'faces/chintu/'+ str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,0,255), 3)\n",
    "        cv2.imshow('Cropping Face', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Training using LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we made at step-1\n",
    "data_path = 'faces/chintu/'\n",
    "# Making sure that files are present and thus checking availbility of all files inside the folder\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Labels ,Training_Data = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in list(enumerate(onlyfiles)):\n",
    "    if i < 150:\n",
    "        image_path = data_path + onlyfiles[i]\n",
    "        #Image Processing to gray for smooth performance on detection\n",
    "        images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #Appending the array of Images with imshow supporting datatype\n",
    "        Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "        Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "chintu_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "# Let's train our model \n",
    "chintu_model.train(Training_Data, Labels)\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Face Recognition Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import smtplib, ssl\n",
    "import pywhatkit\n",
    "import threading\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "def mail(subject,body):\n",
    "\n",
    "# Python code to illustrate Sending mail with attachments\n",
    "# from your Gmail accoun\n",
    "\n",
    "\n",
    "\n",
    "    fromaddr = \"varsha02galav@gmail.com\"\n",
    "    toaddr = \"nishant010singh@gmail.com\"\n",
    "\n",
    "    # instance of MIMEMultipart\n",
    "    msg = MIMEMultipart()\n",
    "\n",
    "    # storing the senders email address\n",
    "    msg['From'] = fromaddr\n",
    "\n",
    "    # storing the receivers email address\n",
    "    msg['To'] = toaddr\n",
    "\n",
    "    # storing the subject\n",
    "    msg['Subject'] = \"Subject of the Mail\"\n",
    "\n",
    "    # string to store the body of the mail\n",
    "    body = \"Body_of_the_mail\"\n",
    "\n",
    "    # attach the body with the msg instance\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    # open the file to be sent\n",
    "    filename = \"newpic.jpg\"\n",
    "    attachment = open(\"./webserver/newpic.jpg\", \"rb\")\n",
    "\n",
    "    # instance of MIMEBase and named as p\n",
    "    p = MIMEBase('application', 'octet-stream')\n",
    "\n",
    "    # To change the payload into encoded form\n",
    "    p.set_payload((attachment).read())\n",
    "\n",
    "    # encode into base64\n",
    "    encoders.encode_base64(p)\n",
    "\n",
    "    p.add_header('Content-Disposition', \"attachment; filename= %s\" % filename)\n",
    "\n",
    "    # attach the instance 'p' to instance 'msg'\n",
    "    msg.attach(p)\n",
    "\n",
    "    # creates SMTP session\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "\n",
    "    # start TLS for security\n",
    "    s.starttls()\n",
    "\n",
    "    # Authentication\n",
    "    s.login(fromaddr, \"wnqbegnpgfzjvsfl\")\n",
    "\n",
    "    # Converts the Multipart msg into a string\n",
    "    text = msg.as_string()\n",
    "\n",
    "    # sending the mail\n",
    "    s.sendmail(fromaddr, toaddr, text)\n",
    "\n",
    "    # terminating the session\n",
    "    s.quit()\n",
    "\n",
    "        \n",
    "def whatsapp(msg,pnumber):\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_hour = now.strftime(\"%H\")\n",
    "    current_minute = now.strftime(\"%M\")\n",
    "    pywhatkit.sendwhatmsg(pnumber, msg, int(current_hour), int(current_minute) + 2)\n",
    "    \n",
    "def automation():\n",
    "    \n",
    "    mail(subject= \"Alert: You are Logged in\",body= \"This is a security Alert do not reply\")\n",
    "    whatsapp(\"Hello This is an automated Message\",\"+919407906253\")\n",
    "    os.system(\"cd webserver && git add newpic.jpg && git commit newpic.jpg -m \\\"latest commit\\\" && git push \")\n",
    "    os.system(\"cd terraform && terraform apply --auto-approve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "stats = True\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = chintu_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is Chintu'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 90:\n",
    "            cv2.putText(image, \"Hello Chintu\", (250, 200), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            if stats:\n",
    "                cv2.putText(image, \"How about hosting your website?\", (50, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.putText(image, \"Enter to Continue / Esc to terminate\", (50, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            else:\n",
    "                 cv2.putText(image, \"Done!\", (50, 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            if keyout == 13:\n",
    "                print (\"inside\")\n",
    "                stats = False\n",
    "                cv2.imwrite(\"webserver/newpic.jpg\", image)\n",
    "                t1 = threading.Thread(target=automation)\n",
    "                t1.start()\n",
    "                print(\"out\")\n",
    "\n",
    "            x = subprocess.getoutput('dir')\n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"You are not Recognized\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Recognizing ..\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    keyout = cv2.waitKey(10)\n",
    "    if keyout == 27: \n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()     \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
